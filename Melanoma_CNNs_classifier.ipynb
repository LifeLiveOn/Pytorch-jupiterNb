{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMR3sSkiS+FMgOUEvfDkz03",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LifeLiveOn/Pytorch-jupiterNb/blob/main/Melanoma_CNNs_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "latpkBE6VZH2",
        "outputId": "2015a226-6031-4132-a0f7-1584d334722b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-03d0a169a81f>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Create datasets and dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMelanomaDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-03d0a169a81f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_file, img_dir, transform)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMelanomaDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Define the dataset class\n",
        "class MelanomaDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, self.data.iloc[idx, 0] + '.jpg')\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        # Extract metadata features\n",
        "        metadata = self.data.iloc[idx, 1:-1].values.astype(float)\n",
        "\n",
        "        label = self.data.iloc[idx, -1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.FloatTensor(metadata), label\n",
        "\n",
        "# Define the CNN model\n",
        "class MelanomaCNN(nn.Module):\n",
        "    def __init__(self, num_metadata_features):\n",
        "        super(MelanomaCNN, self).__init__()\n",
        "        self.efficientnet = models.efficientnet_b0(pretrained=True)\n",
        "        self.efficientnet.classifier = nn.Identity()\n",
        "\n",
        "        self.metadata_fc = nn.Linear(num_metadata_features, 64)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1280 + 64, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img, metadata):\n",
        "        img_features = self.efficientnet(img)\n",
        "        metadata_features = torch.relu(self.metadata_fc(metadata))\n",
        "        combined_features = torch.cat((img_features, metadata_features), dim=1)\n",
        "        return self.classifier(combined_features)\n",
        "\n",
        "# Set up data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = MelanomaDataset('train.csv', 'train_images', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "val_dataset = MelanomaDataset('val.csv', 'val_images', transform=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "num_metadata_features = len(train_dataset[0][1])\n",
        "model = MelanomaCNN(num_metadata_features)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, metadata, labels in train_loader:\n",
        "        images, metadata, labels = images.to(device), metadata.to(device), labels.to(device).float().unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images, metadata)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, metadata, labels in val_loader:\n",
        "            images, metadata, labels = images.to(device), metadata.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(images, metadata)\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss/len(val_loader):.4f}, Val Accuracy: {100*correct/total:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'melanoma_model.pth')\n",
        "\n",
        "# Function for inference\n",
        "def predict(model, image_path, metadata):\n",
        "    model.eval()\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    metadata = torch.FloatTensor(metadata).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image, metadata)\n",
        "        probability = torch.sigmoid(output).item()\n",
        "\n",
        "    return probability\n",
        "\n",
        "# Example usage\n",
        "model.load_state_dict(torch.load('melanoma_model.pth'))\n",
        "probability = predict(model, 'test_image.jpg', [0.5, 0.3, 0.2])  # Replace with actual metadata values\n",
        "print(f\"Probability of melanoma: {probability:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oI-_foiYViyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is my implementation so far"
      ],
      "metadata": {
        "id": "SjaTGySHVjKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "dDSElPe8VlRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# Path to the image folder\n",
        "ImgPath = 'jpeg/train'\n",
        "\n",
        "# Step 1: Filter rows where target == 1 (all of them) and target == 0 (random 1000 samples)\n",
        "data_target_1 = train_data[train_data['target'] == 1]  # All rows where target is 1\n",
        "data_target_0 = train_data[train_data['target'] == 0]  # All rows where target is 0\n",
        "\n",
        "# Step 2: Randomly sample 1000 rows where target == 0\n",
        "sampled_target_0 = data_target_0.sample(n=5000, random_state=42)\n",
        "sampled_target_1 = data_target_1.sample(n=500, random_state=42)\n",
        "\n",
        "# Step 3: Combine both datasets (all target == 1 and 2 random target == 0)\n",
        "combined_data = pd.concat([sampled_target_0, sampled_target_1])\n",
        "\n",
        "# Step 4: Shuffle the combined data to randomize the order\n",
        "combined_data = combined_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Step 5: Preprocess the combined data\n",
        "# Convert sex to numeric\n",
        "combined_data['sex'] = combined_data['sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# Create dummy variables for anatomical site\n",
        "site_dummies = pd.get_dummies(combined_data['anatom_site_general_challenge'], prefix='site')\n",
        "\n",
        "# Combine the DataFrame with the new dummy variables\n",
        "combined_data_processed = pd.concat([combined_data, site_dummies], axis=1)\n",
        "\n",
        "# Drop the original categorical columns\n",
        "columns_to_drop = ['anatom_site_general_challenge', 'diagnosis', 'benign_malignant']\n",
        "combined_data_processed = combined_data_processed.drop(columns_to_drop, axis=1)\n",
        "\n",
        "# Step 6: Select features for modeling\n",
        "feature_columns = ['image_name','age_approx', 'sex'] + list(site_dummies.columns)\n",
        "train_data_for_modeling = combined_data_processed[feature_columns]\n",
        "\n"
      ],
      "metadata": {
        "id": "o5TPwE1mVnIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define a fixed size to resize all images to\n",
        "image_size = (224, 224)\n",
        "\n",
        "# Transformation to convert images to tensors and preprocessing them for training efficiently\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),  # Resizes the image to (128, 128)\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "-jiS93SIVqgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is data_loader.py seperate from jp.ipynb to use parallel computing power of gpu and cpu**"
      ],
      "metadata": {
        "id": "pYfbDl6_WWcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class ImageDataSet(Dataset):\n",
        "    def __init__(self, train_data, path, transform=None):\n",
        "        self.image_names = train_data.iloc[:, 0]\n",
        "        self.metadata = train_data.iloc[:, 1:].astype(np.float32)\n",
        "        self.ImgPath = path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.image_names.iloc[idx]\n",
        "        img_path = os.path.join(self.ImgPath, f\"{image_name}.jpg\")\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        metadata = self.metadata.iloc[idx].values\n",
        "        metadata_tensor = torch.tensor(metadata, dtype=torch.float32)\n",
        "\n",
        "        return image, metadata_tensor\n",
        "\n",
        "# Updated DataLoader function\n",
        "def images_dataloader(train_data, img_folder, batch_size, num_workers=0, device='cuda', flatten=True, transform=None):\n",
        "    try:\n",
        "        dataset = ImageDataSet(train_data, img_folder, transform=transform)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating dataset: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
        "                            num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    all_images = []\n",
        "    all_metadata = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, metadata in tqdm(dataloader, desc=\"Processing batches\"):\n",
        "            images = images.to(device)\n",
        "            metadata = metadata.to(device)\n",
        "\n",
        "            if flatten:\n",
        "                images = images.view(images.size(0), -1)\n",
        "\n",
        "            all_images.append(images.cpu().numpy())\n",
        "            all_metadata.append(metadata.cpu().numpy())\n",
        "\n",
        "    try:\n",
        "        all_images = np.concatenate(all_images, axis=0)\n",
        "        all_metadata = np.concatenate(all_metadata, axis=0)\n",
        "    except Exception as e:\n",
        "        print(f\"Error concatenating data: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    return all_images, all_metadata\n",
        "\n"
      ],
      "metadata": {
        "id": "pz1hmd_ZVrp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**load the data set and image loader to get the data ready for training**"
      ],
      "metadata": {
        "id": "z_zk--yeWgPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from data_loader import images_dataloader\n",
        "img_folder = 'jpeg/train'\n",
        "X_images, X_metadata = images_dataloader(\n",
        "    train_data=train_data_for_modeling,\n",
        "    img_folder=img_folder,\n",
        "    batch_size=64,\n",
        "    num_workers=4,  # Set to 0 if you encounter issues\n",
        "    device=device,\n",
        "    flatten=False,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "D_PGB0bkVtaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply PCA due to large amount of features and different shape so we need to flatten the images, might lose some key features and have to Imputer the NaN data either remove or provide mean"
      ],
      "metadata": {
        "id": "UKTka-PUWq-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"X_images shape: {X_images.shape}\")\n",
        "print(f\"X_metadata shape: {X_metadata.shape}\")\n",
        "pca = PCA(n_components=0.95)\n",
        "X_images_reduced = pca.fit_transform(X_images.reshape(X_images.shape[0], -1))\n",
        "\n",
        "new_combine_traindata = np.hstack((X_images_reduced, X_metadata))"
      ],
      "metadata": {
        "id": "FMVhCH34Vvqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "```\n",
        "X_images shape: (5500, 3, 224, 224)\n",
        "X_metadata shape: (5500, 8)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "b3AM8veYVwwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "y = combined_data['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(new_combine_traindata, y, test_size=0.2, random_state=42)\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')  # You can also use 'median', 'most_frequent', or a constant value\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)"
      ],
      "metadata": {
        "id": "fxyEnYw4V18a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_model = LogisticRegression(random_state=42,max_iter=3000,C=0.1)\n",
        "logistic_model.fit(X_train_imputed, y_train)\n",
        "\n",
        "\n",
        "y_pred = logistic_model.predict(X_test_imputed)\n",
        "y_pred_class = logistic_model.predict(X_test_imputed)  # Class labels\n",
        "y_pred_proba = logistic_model.predict_proba(X_test_imputed)  # Probabilities"
      ],
      "metadata": {
        "id": "PXU09JlQV4Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, log_loss, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "# Metrics\n",
        "accuracy = accuracy_score(y_pred_class, y_test)\n",
        "log_loss_value = log_loss(y_test, y_pred_proba)  # log_loss expects the full probability array\n",
        "f1 = f1_score(y_test, y_pred_class)  # f1_score expects discrete class labels\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Log Loss:\", log_loss_value)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, y_pred_class)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test, y_pred_class)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_class)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "abUd4cpzV5hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aLnS3xohV6mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Accuracy: 0.8936363636363637\n",
        "Log Loss: 0.2769834811995161\n",
        "F1 Score: 0.10687022900763359\n",
        "Precision: 0.3333333333333333\n",
        "Recall: 0.06363636363636363\n",
        "Confusion Matrix:\n",
        " [[976  14]\n",
        " [103   7]]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "EY7shsSkV8Av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "knn_model.fit(X_train_imputed, y_train)\n",
        "\n",
        "\n",
        "y_pred_knn = knn_model.predict(X_test_imputed)\n",
        "\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_f1 = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "print(\"KNN Accuracy:\", knn_accuracy)\n",
        "print(\"KNN F1 Score:\", knn_f1)"
      ],
      "metadata": {
        "id": "6Le1CqX2V9p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "KNN Accuracy: 0.89\n",
        "KNN F1 Score: 0.07633587786259542\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "FRlcqpBVWN3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "nb_model.fit(X_train_imputed, y_train)\n",
        "\n",
        "y_pred_nb = nb_model.predict(X_test_imputed)\n",
        "\n",
        "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
        "nb_f1 = f1_score(y_test, y_pred_nb)\n",
        "\n",
        "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
        "print(\"Naive Bayes F1 Score:\", nb_f1)"
      ],
      "metadata": {
        "id": "QO2ElZKYWPwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "Naive Bayes Accuracy: 0.8054545454545454\n",
        "Naive Bayes F1 Score: 0.27702702702702703\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "0Ho6cF5uWQOJ"
      }
    }
  ]
}